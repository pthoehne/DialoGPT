{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhjmbfi+9YBcaDdIf71qf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4777577d8a21487c865c8e25e2a14868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2c8137113944d7f86aaf372615f3755",
              "IPY_MODEL_2a4bb0c885504ad89ba2193ffa99fbcc",
              "IPY_MODEL_0535168689464d008e9cf8d2d33a0d79"
            ],
            "layout": "IPY_MODEL_6de24cfd273848c0a122bcaa34758ce2"
          }
        },
        "f2c8137113944d7f86aaf372615f3755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc63305324b946afb19cfaaba800b427",
            "placeholder": "​",
            "style": "IPY_MODEL_3e6489e1c4c8459a81caa847880ec498",
            "value": "100%"
          }
        },
        "2a4bb0c885504ad89ba2193ffa99fbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2f91750df44b9ab99b8d69792386b5",
            "max": 20104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d287f7768308499caf4f2f311c0f9ced",
            "value": 20104
          }
        },
        "0535168689464d008e9cf8d2d33a0d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cd3bfffb24843b6bad828ae9cb5591a",
            "placeholder": "​",
            "style": "IPY_MODEL_bb436fa3fb664594b5f2b94636c30766",
            "value": " 20104/20104 [00:00&lt;00:00, 44466.49it/s]"
          }
        },
        "6de24cfd273848c0a122bcaa34758ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "dc63305324b946afb19cfaaba800b427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6489e1c4c8459a81caa847880ec498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b2f91750df44b9ab99b8d69792386b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d287f7768308499caf4f2f311c0f9ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cd3bfffb24843b6bad828ae9cb5591a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb436fa3fb664594b5f2b94636c30766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01ceaa0f895d4a01831969c29e35b2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0ae251e37a44a0f9720aa70c75ed8a7",
              "IPY_MODEL_b4399869e7f441b0b6fcaee0bf2d515a",
              "IPY_MODEL_e8b2dbaa9c4b483fa1ac2db0318c7a25"
            ],
            "layout": "IPY_MODEL_212fb619824d488d9b9db40b4c4f433f"
          }
        },
        "d0ae251e37a44a0f9720aa70c75ed8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af50d727c6604139ba910188a57fa7da",
            "placeholder": "​",
            "style": "IPY_MODEL_1640cc202df947e6a655b4c5cc3089b1",
            "value": "Loss: 2.380 — Avg: 2.454 — GPU Mem: 1510 MB: 100%"
          }
        },
        "b4399869e7f441b0b6fcaee0bf2d515a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c307d3e0db5b443a9a154c085fcd4659",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd67822569034b6eb29f62444434b54a",
            "value": 5000
          }
        },
        "e8b2dbaa9c4b483fa1ac2db0318c7a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f32019cba341f287bde77c1011af52",
            "placeholder": "​",
            "style": "IPY_MODEL_7460d01102e24a6889f9632142236678",
            "value": " 5000/5000 [03:22&lt;00:00, 24.74it/s]"
          }
        },
        "212fb619824d488d9b9db40b4c4f433f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "af50d727c6604139ba910188a57fa7da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1640cc202df947e6a655b4c5cc3089b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c307d3e0db5b443a9a154c085fcd4659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd67822569034b6eb29f62444434b54a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3f32019cba341f287bde77c1011af52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7460d01102e24a6889f9632142236678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pthoehne/DialoGPT/blob/master/Learning_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started with Machine Learning\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*An Introduction to Google Colab, Python and aitextgen*\n",
        "\n"
      ],
      "metadata": {
        "id": "t8nAheIQ8lzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Before we get started**: Save a copy of this notebook in your own Google Drive to keep and edit ('File' > 'Save a Copy in Drive')"
      ],
      "metadata": {
        "id": "X9i4OUay1VBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Working in Google Colab\n",
        "\n",
        "Google Colab is an incredibly useful and user-friendly resource that allow us to write, execute, and share code all in our browsers. These notebooks are cloud-based, meaning all the code execution happens on Google's own servers, **not on your local machine!** So, whenever we download a library or execute code, have no fear that we are downloading strange and arcane code onto your own personal computer - it all stays safely on the cloud. We will download some files onto our actual machines during this session, but nothing will be installed through the execution of code.\n",
        "\n",
        "One of the biggest advantages of Google Colab for machine learning is that it allows us to use a cloud-based GPU! A GPU is a \"Graphics Processing Unit,\" as opposed to a \"Central Processing Unit\" or CPU. While GPUs were made to handle graphical operations, their design makes them ideal for machine learning. GPUs are not always available on colab due to usage constraints, but when they are they allow us to train our models at an accelerated rate. However, this introduction will work for both CPU and GPU training. To try to use a GPU, navigate to 'Runtime' > 'Change runtime type' and select 'GPU.' \n",
        "\n",
        "Because this is a cloud-based resource, the \"instance\" will reset after a period of time or when interrupted. **This means that the models and tokenizers that we generate here are temporary unless we save them locally to our own computers or to our Google Drives.** So, be sure to save any generated files you want to keep, and be sure to re-execute all your code if the runtime is interrupted!\n",
        "\n",
        "Google works with Python, a very handy programming language. You will see a lot of Python code in the course of this tutorial, but again, no fear. **You need no coding experience whatsoever to complete this lesson and begin training your own model!** All of the code is pre-written, and simply requires you to execute it by pressing the 'Run Cell' brackets to the left of the code. Still, I will explain what the code is doing as we make our way through this introduction. **Be sure to run all the cells in order**, as some depend on previous cells having been executed! We will progress through the cells together, so do not worry about having to rush through them all at once.\n",
        "\n",
        "Now, before we go any further, **let's execute some code.**"
      ],
      "metadata": {
        "id": "IvFOZce02SlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Hello World!\")"
      ],
      "metadata": {
        "id": "JEhBvFQc_Hgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5450316c-6b96-40cd-e297-31898fbcab88"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You did it! You executed code, and are now ready to press bravely on into the world of machine learning."
      ],
      "metadata": {
        "id": "kt_C4CKt_h-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Creating a Corpus \n",
        "\n",
        "That was a lot of technical information. Now, let's dive right into preparing the data on which we will train our model.\n",
        "\n",
        "Today, we will be attempting to train a model on a corpus a data source from early 20th-century cookbooks! *The goal is to try to train a model to generate what it thinks a 20th-century should look like, and then to evaluate the promise and limitations of such an approach.*\n",
        "\n",
        "First, however, we need that training material. GPT-2, which is the machine learning model we are using today, trained using .txt files. We will need to create a .txt file large enough to give the model plenty of language on which to train.\n",
        "\n",
        "To do this, we will navigate the [*Early American Cookbooks*](https://babel.hathitrust.org/cgi/mb?a=listis&c=1934413200) collection, curated by Gioia Stevens of NYU Libraries. The collection is hosted on HathiTrust There are two major advantages to this collection. \n",
        "\n",
        "> 1) The works can be downloaded as .txt files. To avoid the delay of logging in, you can download and inspect one such file [here](https://drive.google.com/file/d/1rBT_6qxp5PvNHnevZkIoV_K42vFEORkj/view?usp=sharing). If you would like to download your own texts, sign in, navigate to 'Download' to the left of the text, select '.txt', click 'Whole book,' and hit download. \n",
        "\n",
        "> 2) Critically, this downloaded .txt is full of 'clean' text. The .txt files generated for many historical texts are done through OCR, or optical character  recognition. This automates the work of creating searchable text, but can result in messy and inaccurate outputs. See [this example](https://drive.google.com/file/d/1DsZ7wC4jE6_UJmWP2CXrEoAqUfXZUxqa/view?usp=sharing) from a 1923 issue of the *Omaha Morning Bee* sourced from *Chronicling America*.\n",
        "\n",
        "> Our model will be attempting to learn and replicate whatever text we train it on. It cannot tell 'good' text from 'bad.' So, if we feed it messy input we will get a messy output. Luckily, however, our cookbooks are in [good shape](https://drive.google.com/file/d/1qLrw8DVX_LYk_ebSzrq3A7i_rxXcCZRv/view?usp=sharing). \n",
        "\n",
        ">As you can see, there are some minor issues, but the text looks pretty good.\n",
        "\n",
        "Now, GPT2 benefits from *lots* of text, so our next step now would be to compile a number of similar cookbooks together into one big .txt file that will serve as our **corpus** for training. We would then go through and clean that corpus, deleting the page numbers, indexes, and whatever else we do not want our model learning. In our case, that is everything but the recipes  themselves. However, as we only have a limited time together, I have gone ahead and done this for us. Find the cleaned corpus [here](https://drive.google.com/file/d/1IYbfUR7nepQbnYvo3_f_4N1_FBTqxMff/view?usp=sharing). Go ahead and download that file now, and open it up. You will notice I also added '<|endoftext|>' between the recipes. This serves as a token during training to let the model know where each recipe begins and ends.\n",
        "\n",
        "Now, we have our corpus and it is ready for training! Let's begin.\n",
        "\n"
      ],
      "metadata": {
        "id": "kWUeAeQw8JfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: aitextgen and Training\n",
        "\n",
        "This code will take a little while to execute, so go ahead and run it while I talk a little bit about aitextgen and what we are doing here."
      ],
      "metadata": {
        "id": "9nmTDd--OZZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd_h5rH2FDpI",
        "outputId": "d1db9bd9-aab3-4cb7-aaa6-6ff8bd1b5139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.1/708.1 KB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.2/572.2 KB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -qqy torch torchvision torchtext torchaudio fastai \n",
        "!pip install -qq torch==1.9.0 pytorch-lightning==1.7.7 aitextgen gdown\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO\n",
        "    )\n",
        "\n",
        "from aitextgen import aitextgen\n",
        "from aitextgen.TokenDataset import TokenDataset, merge_datasets\n",
        "from aitextgen.utils import build_gpt2_config\n",
        "from aitextgen.tokenizers import train_tokenizer\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Today, we will be using Max Woolf's [aitextgen](https://docs.aitextgen.io/) to train our model and generate outputs from that trained model. Woolf is a data scientist who created aitextgen in hopes of making it more accessible and simple to work with GPT2. \n",
        "\n",
        "aitextgen is a Python library, so we will need to install it before we start training. Remember, this installation happens in the cloud and not on your personal machine.\n",
        "\n",
        "Let's go ahead and install the necessary libraries now. Execute the code below to begin."
      ],
      "metadata": {
        "id": "bym2CJuIvW5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next**, we need to upload our corpus into the notebook and identify it. To upload the file, click the folder icon on the left side of your screen. This should expand into a window entitled 'Files.' Right click in this window, select 'Upload,' and upload the corpus. \n",
        "\n",
        "Next, we need to identify the corpus file and use it to train a tokenizer. GPT2 turns the strings of letters and words into tokens for its training. This will generate a new file under 'Files' named 'aitextgen.tokenizer.json.'"
      ],
      "metadata": {
        "id": "_53RQFqXQRpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1IYbfUR7nepQbnYvo3_f_4N1_FBTqxMff\n",
        "\n",
        "cookbook_corpus = \"cookbooks_corpus.txt\"\n",
        "\n",
        "train_tokenizer(cookbook_corpus)\n"
      ],
      "metadata": {
        "id": "XhAIPm8XGLjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa50cd5-ba6a-4fe3-b3ab-f26c7836a323"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IYbfUR7nepQbnYvo3_f_4N1_FBTqxMff\n",
            "To: /content/cookbooks_corpus.txt\n",
            "\r  0% 0.00/764k [00:00<?, ?B/s]\r100% 764k/764k [00:00<00:00, 175MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will specify the configurations for our GPT2 build. Most of this refers to the size of the vocabulary used to train the model, the maximum length for the model, token embeddings, and so on. We do not need to adjust this for an introductory session, but if you would like to learn more feel free to explore Woolf's [site](https://docs.aitextgen.io/tutorials/model-from-scratch/).\n",
        "\n",
        "*Note*: to_gpu is set to True, but if you are not able to use a GPU delete 'True' and just type 'False.'\n",
        "\n"
      ],
      "metadata": {
        "id": "DcJ3T2MFWgdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = build_gpt2_config(vocab_size=5000, max_length=512, dropout=0.0, n_embd=256, n_layer=8, n_head=8)\n",
        "\n",
        "ai = aitextgen(config=config,\n",
        "               tokenizer_file=\"aitextgen.tokenizer.json\",\n",
        "               to_gpu=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnlxod-mWf06",
        "outputId": "183e8f1f-e96b-4189-d18a-65a60d0aadea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:aitextgen:Constructing model from provided config.\n",
            "INFO:aitextgen:GPT2 loaded with 7M parameters.\n",
            "INFO:aitextgen:Using a custom tokenizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With that all done, we can try to generate some text. Run the cell below."
      ],
      "metadata": {
        "id": "nhVSYI1KYcsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ai.generate(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k3R99h6GduB",
        "outputId": "21920e54-55f9-49aa-ca73-75e8dae50692"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "&heeseise st�(Jto\u0007eason ucup pin�ne standpe(R ofchooreFinala veal fine choress pinbreadredspoonfulhickenixture the \" cornbread thickenoneave p�\n",
            "==========\n",
            "hardmmerTvery W cookpppp�4oft� beef�\u0007\u0007 whicherer i\u001a��ong�us cook Letho buttered�{endpoonhicken wellP\u0019Egeason wine��ide�hicken water� 1 oz cho tom\n",
            "==========\n",
            "carefullyJro� oun \" F� ses\u001aof/\u0007 pudding or\u0019 5ableable] teaspoonful�flour� ; carefullyissolchowellzzid� allarm�choixtureleanissolved� softell hours_�easina\n",
            "==========\n",
            "vealhop\u000bten72\u0010 water through beat beatJelly 14sauceallyallyally lb crumbstenetwitheasful tea qeas water off When sugarJFrinkleatf ;red{eas�� ozew corn li cooked\u0000ixture� hard\b Then\n",
            "==========\n",
            "he cookeas choeasina cookatoesightly have have cho\u000eoneher fill but but\u0010oilarageut slooeason�with�boileasonasseatenatoesissolved ozasseasg\u001a oz ozafro fine tablespoonful tablespoonful ;eason \"\u0010�urresssalt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That does not look great...because we have not trained our model! \n",
        "\n",
        "It is time to begin training. Run the cell below.\n",
        "\n",
        "This will take a while, even though we have only set this training to 5,000 steps. Every 1,000 steps, the model will generate some sample text so we can see how it is progressing.\n",
        "\n",
        "Some useful notes:\n",
        "\n",
        "**'num_steps'** refers how many 'steps' will occur over the course of training. The more steps, the longer the training and the better the model, as it will allow the model to train over the whole corpus. \n",
        "\n",
        "**'Learning rate'** refers to the size of the training step. We will leave this alone for this introduction. \n",
        "\n",
        "**'batch_size'** refers to the number of batches into which we will divide our tokens at each step of training. Higher batch sizes tend to cause Out of Memory (OOM) errors unless you have access to lots of RAM, so we will keep this at '1.' \n",
        "\n",
        "**'Loss'** and **'average loss'** tell us how are model is doing. Over the course of training, this number should fall. The lower the loss, the better the trained model is performing. \n",
        "\n",
        "For a deeper dive into some of these settings and the concepts behind them, see Chantal Brousseau's excellent [article](https://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt) in the *Programming Historian* (a wonderful resource for learning about many DH tools). "
      ],
      "metadata": {
        "id": "t1GRLYziYhc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ai.train(cookbook_corpus,\n",
        "         line_by_line=False,\n",
        "         from_cache=False,\n",
        "         num_steps=5000,\n",
        "         generate_every=1000,\n",
        "         save_every=1000,\n",
        "         save_gdrive=False,\n",
        "         learning_rate=1e-3,\n",
        "         batch_size=1,\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4777577d8a21487c865c8e25e2a14868",
            "f2c8137113944d7f86aaf372615f3755",
            "2a4bb0c885504ad89ba2193ffa99fbcc",
            "0535168689464d008e9cf8d2d33a0d79",
            "6de24cfd273848c0a122bcaa34758ce2",
            "dc63305324b946afb19cfaaba800b427",
            "3e6489e1c4c8459a81caa847880ec498",
            "4b2f91750df44b9ab99b8d69792386b5",
            "d287f7768308499caf4f2f311c0f9ced",
            "1cd3bfffb24843b6bad828ae9cb5591a",
            "bb436fa3fb664594b5f2b94636c30766",
            "01ceaa0f895d4a01831969c29e35b2a0",
            "d0ae251e37a44a0f9720aa70c75ed8a7",
            "b4399869e7f441b0b6fcaee0bf2d515a",
            "e8b2dbaa9c4b483fa1ac2db0318c7a25",
            "212fb619824d488d9b9db40b4c4f433f",
            "af50d727c6604139ba910188a57fa7da",
            "1640cc202df947e6a655b4c5cc3089b1",
            "c307d3e0db5b443a9a154c085fcd4659",
            "bd67822569034b6eb29f62444434b54a",
            "d3f32019cba341f287bde77c1011af52",
            "7460d01102e24a6889f9632142236678"
          ]
        },
        "id": "G0Zd5X2jGfPu",
        "outputId": "4775e649-3b92-40d5-e823-d1dcfedb660b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:aitextgen:Loading text from cookbooks_corpus.txt with generation length of 512.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20104 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4777577d8a21487c865c8e25e2a14868"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:aitextgen.TokenDataset:Encoding 20,104 sets of tokens from cookbooks_corpus.txt.\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
            "  rank_zero_deprecation(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
            "  rank_zero_deprecation(\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01ceaa0f895d4a01831969c29e35b2a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            " Season with a little fine chopped\n",
            "\n",
            "==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "dfted cayen.-FromFrom “\n",
            "\n",
            "\n",
            "==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "Toast.\n",
            "Scher ätipe stripe a\n",
            "aise fire) end of cold water, 14 of flour and a few minutes).\n",
            "add 12 small\n",
            "adding the\n",
            "add 72 a cup of salt and strain it boil 10 minutes;\n",
            "baking powder. Let it a little\n",
            "Put i\n",
            "y to a few\n",
            "t and stir in a stiff\n",
            "therol, add 1 cup of cream ; stirring\n",
            "the mould\n",
            "chopped onion. Add i pint of a buttered\n",
            "and cook 10 minutes and a few\n",
            "\n",
            "==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "Rocoanut Soup.\n",
            "Cover Ice of water with I\n",
            "tablespoonfuls water; add ½ a teaspoonful of pepper and cook in\n",
            "b it up, and stirring contwarm water), when\n",
            "until quick. Whip in a half a bring\n",
            "melted sugar. Then add a little cold\n",
            "a pint of sugar, and if\n",
            "mouned in a quitead of gelatine.\n",
            "\n",
            "==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=5000` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "–Strawberry wine.\n",
            "\n",
            "==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:aitextgen:Saving trained model pytorch_model.bin to /trained_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The initial training is complete!** Run the cell below to generate text from this short training."
      ],
      "metadata": {
        "id": "7prYaSOZhyOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_folder = \"./trained_model\"\n",
        "\n",
        "tokenizer_file = \"aitextgen.tokenizer.json\"\n",
        "\n",
        "config = \"config.json\"\n",
        "\n",
        "ai2 = aitextgen(tokenizer_file=tokenizer_file, model_folder=model_folder, model=\"pytorch_model.bin\", config=config)\n",
        "\n",
        "ai2.generate(n=5,\n",
        "            max_length=512,\n",
        "            temperature=0.7\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN0Sn7O6nY4S",
        "outputId": "54e621cd-972c-43e3-b471-3fd6bec42417"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:aitextgen:Loading model from provided weights and config in /./trained_model.\n",
            "INFO:aitextgen:GPT2 loaded with 7M parameters.\n",
            "INFO:aitextgen:Using a custom tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-Strientiled Rice Cuttripe.\n",
            "Boil 6 or 3 or vegetables,\n",
            "for ten minutes, and the\n",
            "just before serving.\n",
            "Add a little cold water, salt and\n",
            "and add a little vanilla, a pinch of salt,\n",
            "and stir over the yolks of the eggs\n",
            "well together, and add the whites of 5 eggs\n",
            "and serve cold.\n",
            "\n",
            "==========\n",
            "—Broquettes.\n",
            "When very hot stir in a double boiler with the fire until the\n",
            "for readyr; add i pint of cream\n",
            "well beaten yolks of 4 of 4 eggs and the whites of\n",
            "eggs, a pinch of salt and white wine; then add\n",
            "well to the mixture; stir in the fire and add 1/2 cup-\n",
            "ful of milk and 3 tablespoonfuls of butter ; let boil\n",
            "it gently until tender and then add a few\n",
            "minutes. Stir until the yolks of 4 eggs\n",
            "cream ; then add 1/2 cup of the yolks of 2 tablespoonfuls of\n",
            "lemon and the juice of 12 lemon-\n",
            "lemon and the whites of the eggs and\n",
            "from the whites of the whites of the eggs.\n",
            "Shels and dissolve orange with the piece of\n",
            "and bake in a moderate oven until done.\n",
            "\n",
            "==========\n",
            "–Ston of Liled Oyster.\n",
            "\n",
            "==========\n",
            "Sh Real Sauce.\n",
            "Take a pint of paragusated sugar and 2 eggs, add ½ cupfuls\n",
            "of water, a pint of water, 2 tablespoonfuls\n",
            "of salt and 4 of sugar, the grated\n",
            "butter orange with 2 ounces of salt,\n",
            "brated sugar, 1 lemon peel and 2 ounces\n",
            "s. Boil twenty minutes in the\n",
            "five or ½ pt. of milk, stir all the\n",
            "while and cons until the\n",
            "subegin ap, and add the time white of\n",
            "white with more sugar mixed\n",
            "cakes into a halves.\n",
            "\n",
            "==========\n",
            "—German Shripe.\n",
            "Pour a rich liquortuce the beans with a cup of\n",
            "butter and add 1 tablespoonful of butter, a pinch of\n",
            "butter, a pinch of salt, and\n",
            "toes of a little water, and add\n",
            "the whites of a lemon juice of a lemon juice, and\n",
            "pour cream, and when well mixed, and serve\n",
            "with a rich sauce.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This generated text looks *much* better than the pre-training generated text. Some if it is even beginning to resemble a cookbook. Still, this text is still fragmented and full of errors.\n",
        "\n",
        "**To properly train a robust model takes a *long* time.** We only have an hour together today, and that would not be nearly enough time to train a proper model. \n",
        "\n",
        "So, in the interest of time, I went ahead a trained our corpus ahead of time. This training For good measure, I used a GPU cluster to train this model over the course of **500,000 steps**. This long training brought the loss down to an average of just .081.\n",
        "\n",
        "Go ahead and download the tokenizer [here](https://drive.google.com/file/d/1zhUChyyoFmkF8JNDPAL75MPzUWLZewsU/view?usp=sharing) and the model folder [here](https://drive.google.com/drive/folders/18kOhXcavq4FaGQj6uyKP-KT5RHT726uJ?usp=sharing). Download both files from this folder.\n",
        "\n",
        "**Now upload the tokenizer into the 'Files' window as you did with the corpus earlier. Then, right click in the 'Files' window and select 'New Folder.' Name this folder 'trained_model(cookbooks)' and upload both files from the model folder.**"
      ],
      "metadata": {
        "id": "X8AbrZDiiArW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Exploring a Fully Trained Model \n",
        "\n",
        "Go ahead a run this cell as many times as you want, exploring the generated text! The text will not be perfect, but it will help us evaluate the promises and limitations of using GPT2 and machine learning models as tools for analysis. Share your findings in this [Google Doc](https://docs.google.com/document/d/1kghwCiXj49TJM6mmCpOIir9nPaYAUHjVOUHSmeF_ST0/edit?usp=sharing), and we will explore them together. \n",
        "\n"
      ],
      "metadata": {
        "id": "NUozkT10ZJug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir trained_model_cookbooks"
      ],
      "metadata": {
        "id": "pEKCwXMF9-BC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1zhUChyyoFmkF8JNDPAL75MPzUWLZewsU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcGYkXpe45EL",
        "outputId": "f9e418fa-0904-46ee-ac0f-fd2ab59332a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zhUChyyoFmkF8JNDPAL75MPzUWLZewsU\n",
            "To: /content/aitextgen.tokenizer(cookbooks).json\n",
            "\r  0% 0.00/31.0k [00:00<?, ?B/s]\r100% 31.0k/31.0k [00:00<00:00, 49.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd trained_model_cookbooks\n",
        "\n",
        "!gdown 1jKmdGlT_kYFImY2aHQtIYTVbHwOdGocy \n",
        "!gdown 1zZQRrAvF8DKriIDqHmvT5YEwIbrC4ye3\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6DxvBvx-NaX",
        "outputId": "6cc71c97-fca7-4a12-bf78-e7499557916c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/trained_model_cookbooks\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jKmdGlT_kYFImY2aHQtIYTVbHwOdGocy\n",
            "To: /content/trained_model_cookbooks/config.json\n",
            "100% 780/780 [00:00<00:00, 1.57MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zZQRrAvF8DKriIDqHmvT5YEwIbrC4ye3\n",
            "To: /content/trained_model_cookbooks/pytorch_model.bin\n",
            "100% 35.6M/35.6M [00:00<00:00, 335MB/s]\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_folder = \"./trained_model_cookbooks\"\n",
        "\n",
        "tokenizer_file = \"aitextgen.tokenizer(cookbooks).json\"\n",
        "\n",
        "config = \"config.json\"\n",
        "\n",
        "ai2 = aitextgen(tokenizer_file=tokenizer_file, model_folder=model_folder, model=\"pytorch_model.bin\", config=config)\n",
        "\n",
        "ai2.generate(n=5,\n",
        "            max_length=512,\n",
        "            temperature=0.7\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "6MOaxjVuaf3u",
        "outputId": "e239ed67-b44a-4369-a03e-d3e039196109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-097428a087fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"config.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mai2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maitextgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pytorch_model.bin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m ai2.generate(n=5,\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/aitextgen/aitextgen.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, model_folder, config, vocab_file, merges_file, tokenizer_file, schema_tokens, schema_return, cache_dir, tf_gpt2, to_gpu, to_fp16, verbose, gradient_checkpointing, bos_token, eos_token, unk_token, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             assert not os.path.isfile(model), (\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;34m\"As of aitextgen 0.5.0, you must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m\"use `model_folder` to load an existing model.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: As of aitextgen 0.5.0, you must use `model_folder` to load an existing model."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "You did it! You made it through the steps needed to produce a corpus, train a model, and explore the output. Feel free to return to this guide and tweak any of the settings to your liking. You may also replace our cookbook corpus with a corpus of your own.\n",
        "\n",
        "*Bon Appétit!*\n"
      ],
      "metadata": {
        "id": "3PpgeS3Jo8j2"
      }
    }
  ]
}